[root]
env_name = Pong-v0
n_iter_pretrain = 50000
n_train_steps = 1500000
n_iter_explore = 1000000
minibatch_size = 32
replay_memory_size = 200

nn_arch = conv_3layer
make_recurrent = True
rnn_train_tracelength = 4

double_q_learning = false
hysteretic_q_learning = false
discount = 0.95
epsilon_init = 1.0
epsilon_final = 0.1
target_q_update_period = 1000

eps_test_time = 0.01
