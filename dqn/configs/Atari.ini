[env]
name = Pong-v0
render = false
n_pretrain_steps = 50000
n_explore_steps = 1000000
n_max_steps = 10000000
benchmark_every_n_episodes = 40
benchmark_for_n_episodes = 10

[agent]
nn_arch = AtariConvRecNet
history_length = 4
train_freq = 4
discount = 0.99
epsilon_init = 1.0
epsilon_final = 0.1
epsilon_test_time = 0.05
target_q_update_freq = 10000

[replay_memory]
batch_size = 32
capacity = 1000000
obs_dtype = uint8
