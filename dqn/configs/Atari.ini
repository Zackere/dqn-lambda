[env]
name = Pong-v0
n_pretrain_steps = 50000
n_explore_steps = 1000000
n_max_steps = 10000000
benchmark_every_n_episodes = 100
benchmark_for_n_episodes = 10

[nn]
arch = conv_3layer
recurrent = true
agent_history_length = 4
train_freq = 4

[dqn]
discount = 0.99
epsilon_init = 1.0
epsilon_final = 0.1
epsilon_test_time = 0.05
target_q_update_freq = 10000
double_q_learning = false
minibatch_size = 32
replay_memory_capacity = 1000000
